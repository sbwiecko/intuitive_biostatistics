{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "b51595f36012c8da2bf2284ebbd8d377d5c2d31fa7484164f2d2bcda7a09b462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Quantifying scatter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "data = np.array([64.7, 65.4, 88.3, 64, 71.9])\r\n",
    "#np.concatenate(array_1, array_2, array_3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The variance\r\n",
    "\r\n",
    "The **variance** is a measure of how much the data varies around its mean. There are two different definitions of variance.\r\n",
    "The **population variance** assumes that that we are working with the entire population and is defined as the average squared difference from the mean: $$ \\mathrm{Var}_p(x) = \\frac{1}{n}\\sum_{i = 1}^{n}(x_i - \\overline{x})^2 $$\r\n",
    "\r\n",
    "The **sample variance** assumes that we are working with a sample and attempts to estimate the variance of a larger population by applying [*Bessel's correction*](https://en.wikipedia.org/wiki/Bessel%27s_correction) to account for potential sampling error. The sample variance is: $$ \\mathrm{Var}_s(x) = \\frac{1}{n-1}\\sum_{i = 1}^{n}(x_i - \\overline{x})^2 $$\r\n",
    "\r\n",
    "One can understand Bessel's correction as the degrees of freedom in the residuals vector (residuals, not errors, because the population mean is unknown): $ (x_1 - \\bar{x}, \\dots, x_n - \\bar{x}) $, where $ \\bar{x} $ is the sample mean. While there are $ n $ independent observations in the sample, there are only $ n- 1 $ independent residuals, as they sum to 0.\r\n",
    "\r\n",
    "You can see that $ \\mathrm{Var}_p(x) = \\frac{n - 1}{n}\\mathrm{Var}_s(x) $, so as the data set gets larger, the sample variance and the population variance become less and less distinguishable, which intuitively makes sense."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The standard deviation\r\n",
    "\r\n",
    "Variance does not have intuitive scale relative to the data being studied, because we have used a 'squared distance metric', therefore we can square-root it to get a measure of 'deviance' on the same scale as the data. We call this the *standard deviation* $\\sigma(x)$, where $\\mathrm{Var}(x) = \\sigma(x)^2$.\r\n",
    "\r\n",
    "The standard deviation accounts for the variation among the values, with an estimation of the spread of the distribution:\r\n",
    "$$ \\text{SD} = \\sqrt{\\frac{\\sum(Y_i - \\overline{Y})^2}{n-1}} $$\r\n",
    "\r\n",
    "As with variance, standard deviation has both population and sample versions, and the sample version is calculated by default. Conversion between the two takes the form\r\n",
    "$$ \\sigma_p(x) = \\sqrt{\\frac{n-1}{n}}\\sigma_s(x) $$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(f\"The mean of the dataset is {np.mean(data):.2f} and its standard deviation {np.std(data, ddof=1):.2f}\")\r\n",
    "# by default ddof=0 with np.std()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The mean of the dataset is 70.86 and its standard deviation 10.25\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can interpret the SD from the 3-$\\sigma$ rule of thumb: about 2/3 of the observations in a population usually lie within the rande defined by the mean minus 1 SD to the mean plus 1 SD. So that we have the follwing intervals:\r\n",
    "* \\[-1 SD; 1 SD\\] = 68%\r\n",
    "* \\[-2 SD; 2 SD\\] = 95%\r\n",
    "* \\[-3 SD; 3 SD\\] = 99.7%"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "np.percentile(data, q=[25, 75])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([64.7, 71.9])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "np.var(data, ddof=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "105.01299999999995"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More statistics using scipy.stats"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from scipy import stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### IQR"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "stats.iqr(data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7.200000000000003"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### descriptive summary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "stats.describe(data) # ->nobs, minmax, mean, variance, skewness, kurtosis"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DescribeResult(nobs=5, minmax=(64.0, 88.3), mean=70.86000000000001, variance=105.01299999999995, skewness=1.1912013156755001, kurtosis=-0.24972334599204293)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SEM\n",
    "\n",
    "SEM quantifies how precisely we know the population mean, with the SEM from one sample the best estimate of what SD among sample means would be if we collected an infinite number of samples of a defined size (think about W = t * SEM)\n",
    "\n",
    "$$SEM=\\frac{SD}{\\sqrt{n}}$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "stats.sem(data) # standard error of the mean, i.e. SEM = SD / sqrt(n)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4.582859369433017"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Z-score\n",
    "\n",
    "Or how many SD distant from the mean; we considere an outlier data point with a |Z| > 3."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "stats.zscore(data, ddof=0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.6720695 , -0.59569796,  1.90274222, -0.74844103,  0.11346628])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Coefficient of variation (CV)\n",
    "\n",
    "CV equals the SD divided by the mean; if CV = 0.25, we know that the SD is 25% of the mean (a measure of variability)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "stats.variation(data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1293496858434382"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geometric mean and standard deviation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "stats.gmean(array) # geometric mean, same as\r\n",
    "10**np.mean(np.log10(array))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "85.57807971033304"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "10**np.std(np.log10(array)) # gives the GSD (no unit)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.1038273439921256"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The result is GM*/GSD, i.e. 2/3 of the values in this distribution are within GM/GSD and GM*GSD.\n",
    "\n",
    "The log of the product of 2 values equals the sum of the log of the 1st value + the log of the 2nd value; log converts multiplicative scatter (lognormal dist) to additive scatter (Gaussian). Lognormal dist are common, e.g. potentcy of drug (EC50, IC50, Km, Ki etc.), blood serum concentrations of many natural or toxic compounds etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weighted statistics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from statsmodels.stats.weightstats import DescrStatsW\r\n",
    "\r\n",
    "array = [90, 80, 75, 100, 85]\r\n",
    "weights=[.3, .2,.15, .15, .2]\r\n",
    "\r\n",
    "weighted_stats = DescrStatsW(array, weights=weights, ddof=1)\r\n",
    "print(weighted_stats.mean, weighted_stats.std, weighted_stats.var, sep='\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "86.25\n",
      "inf\n",
      "inf\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}