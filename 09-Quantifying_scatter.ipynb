{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([64.7, 65.4, 88.3, 64, 71.9])\n",
    "#np.concatenate(array_1, array_2, array_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The variance\n",
    "\n",
    "The **variance** is a measure of how much the data varies around its mean. There are two different definitions of variance.\n",
    "The **population variance** assumes that that we are working with the entire population and is defined as the average squared difference from the mean: $$ \\operatorname{Var}_p(x) = \\sigma_p^2(x) = \\frac{1}{n}\\sum_{i = 1}^{n}(x_i - \\overline{x})^2 $$\n",
    "\n",
    "More generally, the variance of a random variable $X$ is the expected value of the squared deviation from the mean of $X$, $ \\mu =\\operatorname{E}[X] $:\n",
    "\n",
    "$$ \\operatorname{Var}(X) = \\operatorname{E} \\left[(X - \\mu)^2\\right] $$\n",
    "\n",
    "The **sample variance** assumes that we are working with a sample and attempts to estimate the variance of a larger population by applying [*Bessel's correction*](https://en.wikipedia.org/wiki/Bessel%27s_correction) to account for potential sampling error. The sample variance is: $$ \\operatorname{Var}_s(x)= \\sigma_s^2(x)  = \\frac{1}{n-1}\\sum_{i = 1}^{n}(x_i - \\overline{x})^2 $$\n",
    "\n",
    "One can understand Bessel's correction as the degrees of freedom in the residuals vector (residuals, not errors, because the population mean is unknown): $ (x_1 - \\bar{x}, \\dots, x_n - \\bar{x}) $, where $ \\bar{x} $ is the sample mean. While there are $ n $ independent observations in the sample, there are only $ n- 1 $ independent residuals, as they sum to 0.\n",
    "\n",
    "You can see that $ \\operatorname{Var}_p(x) = \\frac{n - 1}{n}\\operatorname{Var}_s(x) $, so as the data set gets larger, the sample variance and the population variance become less and less distinguishable, which intuitively makes sense.\n",
    "\n",
    "Note that variance can be decomposed to show that it is also the difference of the mean of squares to the mean squared:\n",
    "\n",
    "$$ \\operatorname{Var}(x) = (\\frac{1}{n}\\sum_{i = 1}^{n}x_i^2) - \\overline{x}^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The standard deviation\n",
    "\n",
    "Variance does not have intuitive scale relative to the data being studied, because we have used a 'squared distance metric', therefore we can square-root it to get a measure of 'deviance' on the same scale as the data. We call this the *standard deviation* $\\sigma(x)$, where $$\\operatorname{Var}(x) = \\sigma^2(x)$$\n",
    "\n",
    "The standard deviation accounts for the variation among the values, with an estimation of the spread of the distribution:\n",
    "$$ \\text{SD} = \\sqrt{\\frac{\\sum(Y_i - \\overline{Y})^2}{n-1}} $$\n",
    "\n",
    "As with variance, standard deviation has both population and sample versions, and the sample version is calculated by default. Conversion between the two takes the form\n",
    "$$ \\sigma_p(x) = \\sqrt{\\frac{n-1}{n}}\\sigma_s(x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the dataset is 70.86 and its standard deviation 10.25\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean of the dataset is {np.mean(data):.2f} and its standard deviation {np.std(data, ddof=1):.2f}\")\n",
    "# by default ddof=0 with np.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret the SD from the 3-$\\sigma$ rule of thumb: about 2/3 of the observations in a population usually lie within the rande defined by the mean minus 1 SD to the mean plus 1 SD. So that we have the follwing intervals:\n",
    "* \\[-1 SD; 1 SD\\] = 68%\n",
    "* \\[-2 SD; 2 SD\\] = 95%\n",
    "* \\[-3 SD; 3 SD\\] = 99.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64.7, 71.9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(data, q=[25, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.01299999999995"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(data, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More statistics using scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.200000000000003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.iqr(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### descriptive summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=5, minmax=(64.0, 88.3), mean=70.86000000000001, variance=105.01299999999995, skewness=1.1912013156755001, kurtosis=-0.24972334599204293)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(data) # ->nobs, minmax, mean, variance, skewness, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Error of the Mean (SEM)\n",
    "\n",
    "SEM quantifies how precisely we know the population mean, with the SEM from one sample the best estimate of what SD among sample means would be if we collected an infinite number of samples of a defined size (think about W = t * SEM)\n",
    "\n",
    "$$ \\mathrm{SE} = \\frac{\\mathrm{SD}}{\\sqrt{n}} $$\n",
    "\n",
    "#### Interlude\n",
    "\n",
    "Let $x = x_1, x_2, \\dots, x_n$ and $y = y_1, y_2, \\dots, y_m$ be samples of two random variables of length $n$ and $m$ respectively. If $m = n$ and $x + y$ is formed from the element-wise sum of $x$ and $y$, it is obvious that the mean of $x + y$ is equal to the sum of the mean of $x$ and the mean of $y$:\n",
    "\n",
    "$$ \\frac{1}{n}\\sum_{i=1}^n x_i + \\frac{1}{n}\\sum_{i=1}^n y_i = \\frac{1}{n}\\sum_{i=1}^n (x_i + y_i) $$\n",
    "\n",
    "We can also demonstrate that if all values are scaled by a constant, the variance is scaled by the square of that constant $ \\operatorname{Var}(aX) = a^2 \\operatorname{Var}(X) $:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Var}(ax) &= \\frac{1}{n}\\sum_{i = 1}^{n}(ax_i - \\overline{ax})^2 \\\\\n",
    "&= \\frac{1}{n}\\sum_{i = 1}^{n}(ax_i - a\\overline{x})^2 \\\\\n",
    "&= \\frac{1}{n}\\sum_{i = 1}^{n}a^2(x_i - \\overline{x})^2 \\\\\n",
    "&= a^2\\left(\\frac{1}{n}\\sum_{i = 1}^{n}(x_i - \\overline{x})^2\\right) \\\\\n",
    "&= a^2\\operatorname{Var}(x)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The variance of a sum of two random variables is given by $ \\operatorname {Var}(aX+bY) = a^2 \\operatorname{Var}(X) + b^2 \\operatorname{Var}(Y) + 2ab \\operatorname{Cov}(X,Y) $, and $ \\operatorname {Var}(aX-bY) = a^2 \\operatorname{Var}(X) + b^2 \\operatorname{Var}(Y) - 2ab \\operatorname{Cov}(X,Y) $ which can be simplified in the case of independent variables:\n",
    "\n",
    "$$ \\operatorname{Var}(X \\pm Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y) $$\n",
    "\n",
    "We can thus derive the formula for the standard error of the mean of $ x = x_1, x_2, \\dots, x_n $:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Var}(\\overline{x}) &= \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{i = 1}^{n}x_i\\right) \\\\\n",
    "&= \\sum_{i = 1}^{n}\\operatorname{Var}\\left(\\frac{1}{n}x_i\\right) \\\\\n",
    "&= \\frac{1}{n^2}\\sum_{i = 1}^{n}\\operatorname{Var}\\left(x_i\\right) \\\\\n",
    "&= \\frac{1}{n^2} n \\operatorname{Var}\\left(x\\right) \\\\\n",
    "&= \\frac{1}{n}\\operatorname{Var}\\left(x\\right) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Since each $x_i$ is independent and identically distributed, the standard error of the mean is the standard deviation of the mean, which is the square root of the variance of the mean. So taking the square root of the previous derivation:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "SE &= \\sqrt{\\operatorname{Var}(\\overline{x})} \\\\\n",
    "&= \\frac{\\sqrt{\\operatorname{Var}(x)}}{\\sqrt{n}} \\\\\n",
    "&= \\frac{\\sigma(x)}{\\sqrt{n}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Finally, the standard error of the difference between the means of $x$ and $y$ (see chapter 30 - Comparing means) can be derived to\n",
    "\n",
    "$$ \\mathrm{SE}_\\mathrm{mean\\_diff} = \\sqrt{\\frac{\\sigma^2(x)}{n} + \\frac{\\sigma^2(y)}{m}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.582859369433017"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.sem(data) # standard error of the mean, i.e. SE = SD / sqrt(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas dataframe's methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean total_donations equals 2350.14\n",
      "The sample variance of the total_donation equals 6232904.51 while the population variance equals 6215297.44\n",
      "By using the equation Var_p = (n-1)/n Var_s, we obtain for the population variance 6215297.44\n"
     ]
    }
   ],
   "source": [
    "# let's get another toy dataset\n",
    "import peopleanalyticsdata as pad\n",
    "\n",
    "# pad.list_sets() # to get the list of the datasets included\n",
    "\n",
    "df = pad.charity_donation()\n",
    "# also from http://peopleanalytics-regression-book.org/data/charity_donation.csv\n",
    "\n",
    "print(f\"The mean total_donations equals {df['total_donations'].mean():.2f}\")\n",
    "\n",
    "var_total_donation_sample = df['total_donations'].var() # normalized by N-1 by default (sample variance)\n",
    "var_total_donation_popul  = df['total_donations'].var(ddof=0)\n",
    "\n",
    "print(f\"The sample variance of the total_donation equals {var_total_donation_sample:.2f} while the population variance equals {var_total_donation_popul:.2f}\")\n",
    "print(f\"By using the equation Var_p = (n-1)/n Var_s, we obtain for the population variance {(1 - 1/len(df)) * var_total_donation_sample:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample standard deviation equals 2496.58 while the square root of the sample variance equals 2496.58\n"
     ]
    }
   ],
   "source": [
    "print(f\"The sample standard deviation equals {df['total_donations'].std(ddof=1):.2f} while the square root of the sample variance equals {var_total_donation_sample**.5:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean and the standard error of the mean for the first 20 entries of total_donations.\n",
    "\n",
    "Calculate the mean and the standard error of the mean for the first 50 entries of total_donations.\n",
    "Verify that the standard error is less than for the first 20 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the first 20 entries of `total donations` = 1851.00 and the SE = 315.09\n"
     ]
    }
   ],
   "source": [
    "mean_total_donation_20 = df.loc[:19, 'total_donations'].mean()\n",
    "sem_total_donation_20  = df.loc[:19, 'total_donations'].sem()\n",
    "\n",
    "print(f\"The mean of the first 20 entries of `total donations` = {mean_total_donation_20:.2f} and the SE = {sem_total_donation_20:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the first 50 entries of `total donations` = 2026.40 and the SE = 240.75\n",
      "Is the standard error less than with 20 entries? True\n"
     ]
    }
   ],
   "source": [
    "mean_total_donation_50 = df.loc[:49, 'total_donations'].mean()\n",
    "sem_total_donation_50  = df.loc[:49, 'total_donations'].sem()\n",
    "\n",
    "print(f\"The mean of the first 50 entries of `total donations` = {mean_total_donation_50:.2f} and the SE = {sem_total_donation_50:.2f}\")\n",
    "print(f\"Is the standard error less than with 20 entries? {sem_total_donation_50 < sem_total_donation_20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score\n",
    "\n",
    "Or how many SD distant from the mean; we considere an outlier data point with a |Z| > 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6720695 , -0.59569796,  1.90274222, -0.74844103,  0.11346628])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.zscore(data, ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of variation (CV)\n",
    "\n",
    "CV equals the SD divided by the mean; if CV = 0.25, we know that the SD is 25% of the mean (a measure of variability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1293496858434382"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.variation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.31861680207386"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.gmean(data) # geometric mean, same as\n",
    "10**np.mean(np.log10(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1288080860787209"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**np.std(np.log10(data)) # gives the GSD (no unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is GM*/GSD, i.e. 2/3 of the values in this distribution are within GM/GSD and GM*GSD.\n",
    "\n",
    "The log of the product of 2 values equals the sum of the log of the 1st value + the log of the 2nd value; log converts multiplicative scatter (lognormal dist) to additive scatter (Gaussian). Lognormal dist are common, e.g. potentcy of drug (EC50, IC50, Km, Ki etc.), blood serum concentrations of many natural or toxic compounds etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.318407960199\n",
      "8.184887667868157\n",
      "66.99238613562025\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "\n",
    "array = [90, 80, 75, 100, 85]\n",
    "weights=[3,  2,  1.5,1.55,2]\n",
    "\n",
    "weighted_stats = DescrStatsW(array, weights=weights, ddof=1)\n",
    "print(weighted_stats.mean, weighted_stats.std, weighted_stats.var, sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35e05afc3bbf8458d25376a416e873cf169d04b2fc4efc2b77204c35b02a6d38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
